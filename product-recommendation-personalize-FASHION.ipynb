{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Product Recommendation Engine with Amazon Personalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we would like to use Amazon.comâ€™s customer rating data to build product recommendation plugin for our website. We will use Amazon Personalize to train the recommender model and to host the recommendation inference. In addition, we will test out the inference and display the items that user rated and items that are recommended for that user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and prepare sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -o ./metadata.json.gz http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles/meta_AMAZON_FASHION.json.gz\n",
    "!curl -o ./ratings.json.gz http://deepyeti.ucsd.edu/jianmo/amazon/categoryFiles/AMAZON_FASHION.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data by:    \n",
    "Justifying recommendations using distantly-labeled reviews and fined-grained aspects. Jianmo Ni, Jiacheng Li, Julian McAuley. Empirical Methods in Natural Language Processing (EMNLP), 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip -f ratings.json.gz\n",
    "!gunzip -f metadata.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading ratings into panda data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "ratings_df = pd.read_json(\"./ratings.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Include only important columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = ratings_df[[\"reviewerID\",\"asin\",\"overall\",\"unixReviewTime\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is how the ratings file look like (first 5 lines)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "personalize = boto3.client('personalize')\n",
    "personalize_runtime = boto3.client('personalize-runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = ratings_df.rename(columns={'reviewerID':'USER_ID', 'asin':'ITEM_ID', 'unixReviewTime':'TIMESTAMP', 'overall':'EVENT_VALUE'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df['EVENT_TYPE'] = \"reviewed\"\n",
    "ratings_df['EVENT_VALUE'] = ratings_df['EVENT_VALUE'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify a bucket and data output location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'recommendation-engine-with-personalize-fashion'\n",
    "filename = \"clean_product_ratings.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter only users' ratings that are > 3, and reformat ratings file for Amazon Personalize input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.to_csv(filename, index=False)\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(\"{}/{}\".format(prefix,filename)).upload_file(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest data to Amazon Personalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Specify naming and threshold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = \"fashion\"\n",
    "iteration = \"2\"\n",
    "review_star_threshold = 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create user-interactions schema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "schema = {\n",
    "    \"type\": \"record\",\n",
    "    \"name\": \"Interactions\",\n",
    "    \"namespace\": \"com.amazonaws.personalize.schema\",\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"USER_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"ITEM_ID\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"TIMESTAMP\",\n",
    "            \"type\": \"long\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"EVENT_TYPE\",\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"EVENT_VALUE\",\n",
    "            \"type\": \"float\"\n",
    "        },\n",
    "    ],\n",
    "    \"version\": \"1.0\"\n",
    "}\n",
    "\n",
    "create_schema_response = personalize.create_schema(\n",
    "    name = \"{}-{}-interaction-schema\".format(base_name, iteration),\n",
    "    schema = json.dumps(schema)\n",
    ")\n",
    "\n",
    "schema_arn = create_schema_response['schemaArn']\n",
    "print(json.dumps(create_schema_response, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Dataset Group**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_group_response = personalize.create_dataset_group(\n",
    "    name = \"{}-{}-dataset-group\".format(base_name, iteration)\n",
    ")\n",
    "\n",
    "dataset_group_arn = create_dataset_group_response['datasetGroupArn']\n",
    "print(json.dumps(create_dataset_group_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_group_response = personalize.describe_dataset_group(\n",
    "        datasetGroupArn = dataset_group_arn\n",
    "    )\n",
    "    status = describe_dataset_group_response[\"datasetGroup\"][\"status\"]\n",
    "    print(\"DatasetGroup: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = \"INTERACTIONS\"\n",
    "create_dataset_response = personalize.create_dataset(\n",
    "    name = \"{}-{}-interaction-dataset\".format(base_name, iteration),\n",
    "    datasetType = dataset_type,\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    schemaArn = schema_arn\n",
    ")\n",
    "\n",
    "dataset_arn = create_dataset_response['datasetArn']\n",
    "print(json.dumps(create_dataset_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attach Policy to S3 Bucket**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "policy = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Id\": \"PersonalizeS3BucketAccessPolicy{}{}\".format(base_name, iteration),\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"PersonalizeS3BucketAccessPolicy\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Principal\": {\n",
    "                \"Service\": \"personalize.amazonaws.com\"\n",
    "            },\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": [\n",
    "                \"arn:aws:s3:::{}\".format(bucket),\n",
    "                \"arn:aws:s3:::{}/*\".format(bucket)\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "s3.put_bucket_policy(Bucket=bucket, Policy=json.dumps(policy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Personalize Role**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"PersonalizeRoleForRecommendation{}{}\".format(base_name, iteration)\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"personalize.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonPersonalizeFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Action\": \"s3:*\",\n",
    "          \"Resource\":\"*\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "response = iam.create_policy(\n",
    "    PolicyName='PersonalizeToS3{}{}'.format(base_name, iteration),\n",
    "    PolicyDocument=json.dumps(role_policy_document)\n",
    ")\n",
    "\n",
    "response = iam.attach_role_policy(\n",
    "    RoleName=role_name, PolicyArn=response['Policy']['Arn'])\n",
    "\n",
    "time.sleep(60) # wait for a minute to allow IAM role policy attachment to propagate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create dataset import job**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset_import_job_response = personalize.create_dataset_import_job(\n",
    "    jobName = \"{}-{}-interaction-import-job\".format(base_name, iteration),\n",
    "    datasetArn = dataset_arn,\n",
    "    dataSource = {\n",
    "        \"dataLocation\": \"s3://{}/{}/{}\".format(bucket, prefix, filename)\n",
    "    },\n",
    "    roleArn = role_arn\n",
    ")\n",
    "\n",
    "dataset_import_job_arn = create_dataset_import_job_response['datasetImportJobArn']\n",
    "print(json.dumps(create_dataset_import_job_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait for Dataset Import Job to Have ACTIVE Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_dataset_import_job_response = personalize.describe_dataset_import_job(\n",
    "        datasetImportJobArn = dataset_import_job_arn\n",
    "    )\n",
    "    status = describe_dataset_import_job_response[\"datasetImportJob\"]['status']\n",
    "    print(\"DatasetImportJob: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select Recipe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_recipes_response = personalize.list_recipes()\n",
    "recipe_arn_up = \"arn:aws:personalize:::recipe/aws-user-personalization\"\n",
    "recipe_arn_hrnn = \"arn:aws:personalize:::recipe/aws-hrnn\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Solution Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "solution_config = {\n",
    "        \"eventValueThreshold\": str(review_star_threshold),\n",
    "        \"featureTransformationParameters\": {\n",
    "            \"min_user_history_length_percentile\" : \"0.0\", # increase to remove popular item\n",
    "            \"max_user_history_length_percentile\" : \"0.99\", # stay\n",
    "        },\n",
    "        \"algorithmHyperParameters\": {\n",
    "            \"hidden_dimension\" : \"159\"\n",
    "        },\n",
    "        \"hpoConfig\": {\n",
    "            \"algorithmHyperParameterRanges\": {\n",
    "                'integerHyperParameterRanges': [\n",
    "                    {\n",
    "                        'name': 'bptt', # decrease to discard long-term factor that results to purchases\n",
    "                        'minValue': 3,\n",
    "                        'maxValue': 10\n",
    "                    },\n",
    "                ],\n",
    "                \"continuousHyperParameterRanges\": [],\n",
    "                'categoricalHyperParameterRanges': [\n",
    "                    #{\n",
    "                    #    'name': 'recency_mask', # set to false for discarding recency factor of purchases\n",
    "                    #    'values': ['true','false']\n",
    "                    #},\n",
    "                ],\n",
    "            },\n",
    "            \"hpoResourceConfig\": {\n",
    "                \"maxNumberOfTrainingJobs\": \"40\",\n",
    "                \"maxParallelTrainingJobs\": \"10\"\n",
    "            }\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Solution for User Personalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_solution_response_up = personalize.create_solution(\n",
    "    name = \"{}-{}-up-solution2\".format(base_name, iteration),\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = recipe_arn_up,\n",
    "    eventType = 'reviewed',\n",
    "    performHPO = True,\n",
    "    solutionConfig = solution_config\n",
    ")\n",
    "\n",
    "create_solution_response_hrnn = personalize.create_solution(\n",
    "    name = \"{}-{}-hrnn-solution2\".format(base_name, iteration),\n",
    "    datasetGroupArn = dataset_group_arn,\n",
    "    recipeArn = recipe_arn_hrnn,\n",
    "    eventType = 'reviewed',\n",
    "    performHPO = True,\n",
    "    solutionConfig = solution_config\n",
    ")\n",
    "\n",
    "solution_arn_up = create_solution_response_up['solutionArn']\n",
    "solution_arn_hrnn = create_solution_response_hrnn['solutionArn']\n",
    "print(json.dumps(create_solution_response_up, indent=2))\n",
    "print(json.dumps(create_solution_response_hrnn, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Solution Version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_solution_version_response_up = personalize.create_solution_version(\n",
    "    solutionArn = solution_arn_up\n",
    ")\n",
    "\n",
    "create_solution_version_response_hrnn = personalize.create_solution_version(\n",
    "    solutionArn = solution_arn_hrnn\n",
    ")\n",
    "\n",
    "solution_version_arn_up = create_solution_version_response_up['solutionVersionArn']\n",
    "solution_version_arn_hrnn = create_solution_version_response_hrnn['solutionVersionArn']\n",
    "print(json.dumps(create_solution_version_response_up, indent=2))\n",
    "print(json.dumps(create_solution_version_response_hrnn, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait for Solution Version to Have ACTIVE Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize.describe_solution_version(\n",
    "        solutionVersionArn = solution_version_arn_up\n",
    "    )\n",
    "    status = describe_solution_version_response[\"solutionVersion\"][\"status\"]\n",
    "    print(\"SolutionVersion: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_solution_version_response = personalize.describe_solution_version(\n",
    "        solutionVersionArn = solution_version_arn_hrnn\n",
    "    )\n",
    "    status = describe_solution_version_response[\"solutionVersion\"][\"status\"]\n",
    "    print(\"SolutionVersion: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Metrics of Solution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_solution_metrics_response_up = personalize.get_solution_metrics(\n",
    "    solutionVersionArn = solution_version_arn_up\n",
    ")\n",
    "get_solution_metrics_response_hrnn = personalize.get_solution_metrics(\n",
    "    solutionVersionArn = solution_version_arn_hrnn\n",
    ")\n",
    "\n",
    "print(json.dumps(get_solution_metrics_response_up, indent=2))\n",
    "print(json.dumps(get_solution_metrics_response_hrnn, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Campaign**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_campaign_response_up = personalize.create_campaign(\n",
    "    name = \"{}-{}-campaign-up\".format(base_name, iteration),\n",
    "    solutionVersionArn = solution_version_arn_up,\n",
    "    minProvisionedTPS = 1\n",
    ")\n",
    "create_campaign_response_hrnn = personalize.create_campaign(\n",
    "    name = \"{}-{}-campaign-hrnn\".format(base_name, iteration),\n",
    "    solutionVersionArn = solution_version_arn_hrnn,\n",
    "    minProvisionedTPS = 1\n",
    ")\n",
    "\n",
    "campaign_arn_up = create_campaign_response_up['campaignArn']\n",
    "campaign_arn_hrnn = create_campaign_response_hrnn['campaignArn']\n",
    "print(json.dumps(create_campaign_response_up, indent=2))\n",
    "print(json.dumps(create_campaign_response_hrnn, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wait for Campaign to Have ACTIVE Status**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize.describe_campaign(\n",
    "        campaignArn = campaign_arn_up\n",
    "    )\n",
    "    status = describe_campaign_response[\"campaign\"][\"status\"]\n",
    "    print(\"Campaign: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_campaign_response = personalize.describe_campaign(\n",
    "        campaignArn = campaign_arn_hrnn\n",
    "    )\n",
    "    status = describe_campaign_response[\"campaign\"][\"status\"]\n",
    "    print(\"Campaign: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and upload product metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'metadata.json'\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(\"{}/{}\".format(prefix,filename)).upload_file(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare method to enrich the items information with title and image URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def encrich_with_metadata(products):\n",
    "    client = boto3.client('s3')\n",
    "    r = client.select_object_content(\n",
    "        Bucket=bucket,\n",
    "        Key=\"{}/metadata.json\".format(prefix),\n",
    "        Expression=\"SELECT s.image, s.asin, s.title FROM S3Object s WHERE s.asin IN {}\".format(products),\n",
    "        #Expression=\"SELECT s.imUrl, s.asin, s.title FROM S3Object s WHERE s.asin IN {}\".format(products),\n",
    "        ExpressionType='SQL',\n",
    "        RequestProgress={\n",
    "            'Enabled': False\n",
    "        },\n",
    "        InputSerialization={\n",
    "            'JSON': {\n",
    "                'Type': 'LINES'\n",
    "            }\n",
    "        },\n",
    "        OutputSerialization={\n",
    "            'JSON':{\n",
    "                'RecordDelimiter': '\\n',\n",
    "            }\n",
    "        },\n",
    "    )\n",
    "    output = []\n",
    "    for event in r['Payload']:\n",
    "        if 'Records' in event:\n",
    "            recs = event['Records']['Payload'].decode('utf-8').strip().split(\"\\n\")\n",
    "            recs = list(map(lambda x: json.loads(x), recs))\n",
    "            output += recs\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build filter to exlude items that user has purchased and reviewed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_response = personalize.create_filter(\n",
    "    name='{}-{}-exclude-purchases'.format(base_name, iteration),\n",
    "    datasetGroupArn= dataset_group_arn,\n",
    "    filterExpression= 'EXCLUDE ItemID WHERE Interactions.event_type IN (\"reviewed\")'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = time.time() + 3*60*60 # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_filter_response = personalize.describe_filter(\n",
    "        filterArn = filter_response['filterArn']\n",
    "    )\n",
    "    status = describe_filter_response[\"filter\"][\"status\"]\n",
    "    print(\"Filter: {}\".format(status))\n",
    "    \n",
    "    if status == \"ACTIVE\" or status == \"CREATE FAILED\":\n",
    "        break\n",
    "        \n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get a sample user to test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a user who has considerable number of reviews\n",
    "#user_id = ratings_df[ratings_df['EVENT_VALUE'] >= review_star_threshold]['USER_ID'].value_counts()[:2000].index.to_list()[1995]\n",
    "user_id = ratings_df[ratings_df['EVENT_VALUE'] >= review_star_threshold]['USER_ID'].value_counts()[:2000].index.to_list()[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define method to display items for view purpose**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def display_items(items):\n",
    "    image_string = \"\"\n",
    "    i = 1\n",
    "    for item in items:\n",
    "        if 'score' in item:\n",
    "            caption = \"{}---Score:{}---Name: {}---ASIN:{}\".format(str(i),item['score'], item['title'],item['asin'])\n",
    "        else:\n",
    "            caption = \"{}---Name: {}---ASIN:{}\".format(str(i),item['title'],item['asin'])\n",
    "        if len(item['image']) > 0:\n",
    "            image = item['image'][0]\n",
    "            image = re.sub(r'SR..,..','SR200,200',image)\n",
    "            image = re.sub(r'US..','US200',image)\n",
    "            image = re.sub(r'SS..','SS200',image)\n",
    "            image = re.sub(r'SX..','SX200',image)\n",
    "            image = re.sub(r'SY..','SX200',image)\n",
    "            image = re.sub(r'CR,0,0,..,..','CR,0,0,200,200',image)\n",
    "            image_string += '<figure style=\"float:left;\"><img src=\"{}\" alt=\"\" width=\"1\"/><figcaption ><center>{}</center></figcaption></figure></br>'.format(image,caption)\n",
    "        else:\n",
    "            image_string += '<figure style=\"float:left;\"><img src=\"\" alt=\"\" width=\"1\"/><figcaption ><center>{}</center></figcaption></figure></br>'.format(caption)\n",
    "        i = i+1\n",
    "    return image_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get actual items that user reviewed with rating > 3 and enrich with title and image URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_item_list = list(ratings_df[(ratings_df[\"USER_ID\"] == user_id) & (ratings_df['EVENT_VALUE'] >= review_star_threshold)]['ITEM_ID'])\n",
    "actual_items = encrich_with_metadata(actual_item_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(data=display_items(actual_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get recommendation for user personalize recipe and enrich recommended items with title and images**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_response_up = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn_up,\n",
    "    userId = str(user_id),\n",
    "    numResults=10,\n",
    "    filterArn=filter_response['filterArn']\n",
    ")\n",
    "\n",
    "recommended_item_list = list(map(lambda x: x['itemId'], get_recommendations_response_up['itemList']))\n",
    "print(get_recommendations_response_up['itemList'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare for display**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_items = encrich_with_metadata(recommended_item_list)\n",
    "items_dictionary = {}\n",
    "for item in get_recommendations_response_up['itemList']:\n",
    "    items_dictionary[item['itemId']]=item['score']                                           \n",
    "for item in recommended_items:\n",
    "    item['score'] = items_dictionary[item['asin']]\n",
    "recommended_items.sort(key=lambda x: x['score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These are the actual items that user reviewed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(data=display_items(recommended_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get recommendation for user personalize recipe and enrich recommended items with title and images**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_response_hrnn = personalize_runtime.get_recommendations(\n",
    "    campaignArn = campaign_arn_hrnn,\n",
    "    userId = str(user_id),\n",
    "    numResults=10,\n",
    "    filterArn=filter_response['filterArn']\n",
    ")\n",
    "\n",
    "recommended_item_list = list(map(lambda x: x['itemId'], get_recommendations_response_hrnn['itemList']))\n",
    "print(get_recommendations_response_hrnn['itemList'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare for display**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_items = encrich_with_metadata(recommended_item_list)\n",
    "items_dictionary = {}\n",
    "for item in get_recommendations_response_hrnn['itemList']:\n",
    "    items_dictionary[item['itemId']]=item['score']                                           \n",
    "for item in recommended_items:\n",
    "    item['score'] = items_dictionary[item['asin']]\n",
    "recommended_items.sort(key=lambda x: x['score'], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**These are the actual items that user reviewed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(data=display_items(recommended_items))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
